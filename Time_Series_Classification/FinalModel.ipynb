{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOHLTtnQYp6c"
      },
      "source": [
        "######Google Drive, import libraries and data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI7N_MxmvgiJ",
        "outputId": "8a032db4-8e17-4a15-8a9c-1cf21019303c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5FKTEMkn1SZ",
        "outputId": "b6766020-0970-479e-ff15-f436dc492287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Challenge2\n"
          ]
        }
      ],
      "source": [
        "%cd /gdrive/MyDrive/Challenge2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd8MfGTEn3hp",
        "outputId": "cf1e29eb-6fc2-4df8-997c-a0dc248c8c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  training_dataset_homework2.zip\n",
            "  inflating: y_train.npy             \n",
            "  inflating: x_train.npy             \n"
          ]
        }
      ],
      "source": [
        "#!unzip training_dataset_homework2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw265dpMn8xg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16) \n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "import logging\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "\n",
        "# Random seed for reproducibility\n",
        "seed = 127\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV_UlZngyXep"
      },
      "outputs": [],
      "source": [
        "X = np.load(\"x_train.npy\")\n",
        "y = np.load(\"y_train.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8SAiR2jychw"
      },
      "outputs": [],
      "source": [
        "#Split into train-validation (our test) set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SVU0XZ0ynB4"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "cws = class_weight.compute_class_weight(class_weight = \"balanced\" , classes = np.unique(y_train), y= y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1YqvcMpyv3g"
      },
      "outputs": [],
      "source": [
        "# Convert the sparse labels to categorical values\n",
        "y_train = tfk.utils.to_categorical(y_train)\n",
        "y_val = tfk.utils.to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9_a0gmy0qZ"
      },
      "source": [
        "####Training and Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_DAJO74y4R5"
      },
      "outputs": [],
      "source": [
        "input_shape = X.shape[1:]\n",
        "classes = y_train.shape[-1]\n",
        "batch_size = 32 #64\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o573sCe_zKZ2"
      },
      "source": [
        "#####LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrM6zkCDy5jf"
      },
      "outputs": [],
      "source": [
        "def build_LSTM_classifier(input_shape, classes):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    # Feature extractor\n",
        "    lstm = tfkl.LSTM(128,return_sequences=True)(input_layer)\n",
        "    lstm = tfkl.LSTM(128)(lstm)\n",
        "    dropout = tfkl.Dropout(.2, seed=seed)(lstm)\n",
        "\n",
        "    # Classifier\n",
        "\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    dropout = tfkl.Dropout(.2, seed=seed)(classifier)\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKrsklWnzTxf"
      },
      "outputs": [],
      "source": [
        "lstm = build_LSTM_classifier(input_shape, classes)\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2hQDNyYzMv3"
      },
      "source": [
        "#####Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmW69IjHzAkA"
      },
      "outputs": [],
      "source": [
        "def build_1DCNN_classifier(input_shape, classes):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    # Feature extractor\n",
        "    cnn = tfkl.Conv1D(128,3,padding='same',activation='relu')(input_layer)\n",
        "    cnn = tfkl.AveragePooling1D()(cnn)# \n",
        "    cnn = tfkl.Conv1D(256,3,padding='valid',activation='relu')(cnn)\n",
        "    gap = tfkl.GlobalAveragePooling1D()(cnn)\n",
        "    dropout = tfkl.Dropout(.3, seed=seed)(gap)\n",
        "\n",
        "    # Classifier\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    dropout = tfkl.Dropout(.3, seed=seed)(classifier)\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J3R1gzGzdlg"
      },
      "outputs": [],
      "source": [
        "cnn1 = build_1DCNN_classifier(input_shape, classes)\n",
        "cnn1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm5ST__rzEc4"
      },
      "outputs": [],
      "source": [
        "def build_1DCNN_classifier2(input_shape, classes):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    # Feature extractor\n",
        "    cnn = tfkl.Conv1D(16,3,padding='same',activation='relu')(input_layer)\n",
        "    cnn = tfkl.Conv1D(32,3,padding='same',activation='relu')(cnn)\n",
        "    cnn = tfkl.Conv1D(64,3,padding='same',activation='relu')(cnn)\n",
        "\n",
        "    gap = tfkl.GlobalAveragePooling1D()(cnn)\n",
        "    dropout = tfkl.Dropout(.3, seed=seed)(gap)\n",
        "\n",
        "    # Classifier\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    dropout = tfkl.Dropout(.3, seed=seed)(classifier)\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf6j0peQzeIA"
      },
      "outputs": [],
      "source": [
        "cnn2 = build_1DCNN_classifier2(input_shape, classes)\n",
        "cnn2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD0S33cnzIBA"
      },
      "outputs": [],
      "source": [
        "def build_1DCNN_classifier3(input_shape, classes):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    # Feature extractor\n",
        "    cnn = tfkl.Conv1D(128,3,padding='same',activation='relu')(input_layer)\n",
        "    cnn = tfkl.Conv1D(256,3,dilation_rate = 2,padding='same',activation='relu')(cnn)\n",
        "    gap = tfkl.GlobalAveragePooling1D()(cnn)\n",
        "    dropout = tfkl.Dropout(.3, seed=seed)(gap)\n",
        "\n",
        "    # Classifier\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    dropout = tfkl.Dropout(.3, seed=seed)(classifier)\n",
        "    classifier = tfkl.Dense(128, activation='relu')(dropout)\n",
        "    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4Ih1agZzSqP"
      },
      "outputs": [],
      "source": [
        "cnn3 = build_1DCNN_classifier3(input_shape, classes)\n",
        "cnn3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT6NqLU5zO2v"
      },
      "source": [
        "#####ConvLstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv4YqG6tzQZn"
      },
      "outputs": [],
      "source": [
        "def build_CONV_LSTM_model(input_shape, classes):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    convlstm = tfkl.Conv1D(32, 3, padding='same', activation='relu')(input_layer)\n",
        "    convlstm = tfkl.Conv1D(64, 3, padding='same', activation='relu')(convlstm)\n",
        "    convlstm = tfkl.Conv1D(128, 3, padding='same', activation='relu')(convlstm)\n",
        "\n",
        "    convlstm = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True))(convlstm)\n",
        "    convlstm = tfkl.Bidirectional(tfkl.LSTM(128))(convlstm)\n",
        "\n",
        "    convlstm = tfkl.Dropout(.2)(convlstm)\n",
        "\n",
        "    convlstm = tfkl.Dense(64, activation='relu')(convlstm)\n",
        "\n",
        "    convlstm = tfkl.Dropout(.2, seed=seed)(convlstm)\n",
        "\n",
        "    convlstm = tfkl.Dense(64, activation='relu')(convlstm)\n",
        "\n",
        "    output_layer = tfkl.Dense(classes, activation='softmax')(convlstm)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StgDQ7tTzn0A"
      },
      "outputs": [],
      "source": [
        "convlstm = build_CONV_LSTM_model(input_shape=input_shape, classes = 12)\n",
        "convlstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRiAmFc3zr2O"
      },
      "source": [
        "#####Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9B8YL1IztTI"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model = cnn1 #name of the model to train\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = 300,\n",
        "    validation_data= (X_val,y_val),\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=70, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=30, factor=0.5, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk8oobH80HM-"
      },
      "source": [
        "#####Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#final_model = tfk.models.load_model(\"FinalSubmission\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UTSqzgF0Gg3"
      },
      "outputs": [],
      "source": [
        "cnn1._name = \"cnn1\"\n",
        "cnn2._name = \"cnn2\"\n",
        "cnn3._name = \"cnn3\"\n",
        "lstm._name = 'lstm'\n",
        "convlstm._name = 'convlstm'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_AmpCNl0JJQ"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "\n",
        "models.append(cnn1)\n",
        "models.append(cnn2)\n",
        "models.append(cnn3)\n",
        "models.append(convlstm)\n",
        "models.append(lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaK0kONe0LDg"
      },
      "outputs": [],
      "source": [
        "def ensembleModels(models, model_input):\n",
        "    # collect outputs of models in a list\n",
        "    yModels=[model(model_input) for model in models] \n",
        "    # averaging outputs\n",
        "    yAvg=tfk.layers.average(yModels) \n",
        "    # build model from same input and avg output\n",
        "    modelEns = tfk.Model(inputs=model_input, outputs=yAvg,    name='ensemble')  \n",
        "   \n",
        "    return modelEns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsQTUj0-0Lag"
      },
      "outputs": [],
      "source": [
        "model_input = tfk.Input(shape=models[0].input_shape[1:]) \n",
        "modelEns = ensembleModels(models,model_input)\n",
        "modelEns.compile(optimizer=tfk.optimizers.Adam(),\n",
        "              loss=tfk.losses.CategoricalCrossentropy(),\n",
        "              metrics='accuracy')\n",
        "modelEns.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbVfdyix0MkX"
      },
      "outputs": [],
      "source": [
        "# modelEns.save(\"3cnn+lstm+convlstm\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YOHLTtnQYp6c",
        "o573sCe_zKZ2",
        "K2hQDNyYzMv3",
        "GT6NqLU5zO2v",
        "iRiAmFc3zr2O",
        "Qk8oobH80HM-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
