{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Final Model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "irk2zsGWtaic"
      },
      "outputs": [],
      "source": [
        "# dataset_dir = 'training_data_final'\n",
        "# !pip install split-folders\n",
        "# import splitfolders\n",
        "# splitfolders.ratio(\"training_data_final\", \"ok\", seed=127, ratio=(0.8, 0.2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lFi6GnyTyE5x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IS6M8jscyJx9"
      },
      "outputs": [],
      "source": [
        "# Utility function to create folders and callbacks for training\n",
        "from datetime import datetime\n",
        "\n",
        "def create_folders_and_callbacks(model_name):\n",
        "\n",
        "  exps_dir = os.path.join('model_16_11_split')\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "      \n",
        "  callbacks = []\n",
        "\n",
        "  # Model checkpoint\n",
        "  # ----------------\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
        "                                                     save_weights_only=True, # True to save only weights\n",
        "                                                     save_best_only=False) # True to save only the best epoch \n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Visualize Learning on Tensorboard\n",
        "  # ---------------------------------\n",
        "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "  if not os.path.exists(tb_dir):\n",
        "      os.makedirs(tb_dir)\n",
        "      \n",
        "  # By default shows losses and metrics for both training and validation\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
        "                                               profile_batch=0,\n",
        "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
        "  callbacks.append(tb_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  # --------------\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
        "  callbacks.append(es_callback)\n",
        "\n",
        "  return callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ninrvoAPyLGX"
      },
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 127\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVyqhglfyRN7",
        "outputId": "7a647419-4625-4585-b20c-1cb123a76b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2829 images belonging to 8 classes.\n",
            "Found 706 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch = 32\n",
        "\n",
        "data_gen = ImageDataGenerator(\n",
        "                              width_shift_range=10,\n",
        "                              vertical_flip=True, \n",
        "                              fill_mode='reflect',\n",
        "                              channel_shift_range=20,\n",
        "                              rescale=1/255.)\n",
        "\n",
        "validation_gen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "\n",
        "train_gen = data_gen.flow_from_directory(directory=\"ok/train\",\n",
        "                                                           target_size=(96,96),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None,\n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=batch,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed) # set as training data\n",
        "\n",
        "val_gen = validation_gen.flow_from_directory(directory=\"ok/val\",\n",
        "                                                           target_size=(96,96),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None,\n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=batch,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed) # set as validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qc4XVTdMyMXg"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape):\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=24,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(input_layer)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(conv1)\n",
        "\n",
        "    pool2 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv2)\n",
        "\n",
        "    bn = tfkl.BatchNormalization()(pool2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(bn)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(conv3)\n",
        "    \n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(conv4)      \n",
        "\n",
        "    pool5 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv5)\n",
        "\n",
        "    bn = tfkl.BatchNormalization()(pool5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=96,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(bn)\n",
        "\n",
        "    pool6 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv6)  \n",
        "\n",
        "    bn = tfkl.BatchNormalization()(pool6)  \n",
        "    \n",
        "    conv7 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(bn)\n",
        "\n",
        "    global_pool = tfkl.GlobalMaxPooling2D()(conv7)\n",
        "\n",
        "    bn = tfkl.BatchNormalization()(global_pool) \n",
        "\n",
        "    dropout = tfkl.Dropout(0.2, seed=seed)(bn)\n",
        "\n",
        "    classifier_layer = tfkl.Dense(\n",
        "        units=256, \n",
        "        name='Classifier', \n",
        "        activation='relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(dropout)\n",
        "\n",
        "    dropout = tfkl.Dropout(0.2, seed=seed)(classifier_layer)\n",
        "\n",
        "    classifier_layer2 = tfkl.Dense(\n",
        "        units=256, \n",
        "        name='Classifier2', \n",
        "        activation='relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(dropout)\n",
        "\n",
        "    dropout = tfkl.Dropout(0.2, seed=seed)(classifier_layer2)\n",
        "    \n",
        "    output_layer = tfkl.Dense(\n",
        "        units=8, \n",
        "        activation='softmax', \n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name='Output'\n",
        "    )(dropout)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y0DNgUS90Msp"
      },
      "outputs": [],
      "source": [
        "input_shape = (96, 96, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAM3zzea0KN8",
        "outputId": "34ff351f-a245-4399-ed04-9e8d3f3ad284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 96, 96, 24)        672       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 96, 96, 32)        6944      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 48, 48, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 24, 24, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 24, 24, 96)        55392     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 12, 12, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12, 12, 96)       384       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 128)       110720    \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 128)              0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " Classifier2 (Dense)         (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 8)                 2056      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 368,232\n",
            "Trainable params: 367,592\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model(input_shape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create class weights\n",
        "class_distribution = []\n",
        "for i in range(8):\n",
        "  class_distribution.append(sum(1 for x in train_gen.labels if x == i))\n",
        "  \n",
        "weights = []\n",
        "total = train_gen.labels.size\n",
        "\n",
        "for i in range(8):\n",
        "  weights.append((i,(1/class_distribution[i]) * (total/8.0)))\n",
        "\n",
        "class_weight  = {c:weight for (c,weight) in weights}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_-TDd9qz5Xs",
        "outputId": "9300271e-c657-43d4-87c1-b12005ed0a23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "89/89 [==============================] - 78s 821ms/step - loss: 2.1606 - accuracy: 0.2891 - val_loss: 2.0037 - val_accuracy: 0.2068\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 77s 861ms/step - loss: 1.7282 - accuracy: 0.3517 - val_loss: 1.7283 - val_accuracy: 0.2975\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 80s 899ms/step - loss: 1.5714 - accuracy: 0.4100 - val_loss: 1.8625 - val_accuracy: 0.2904\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 77s 865ms/step - loss: 1.4622 - accuracy: 0.4592 - val_loss: 1.3268 - val_accuracy: 0.5142\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 75s 845ms/step - loss: 1.3944 - accuracy: 0.4783 - val_loss: 1.4593 - val_accuracy: 0.4547\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 74s 834ms/step - loss: 1.3480 - accuracy: 0.5072 - val_loss: 1.2529 - val_accuracy: 0.5297\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 76s 856ms/step - loss: 1.2890 - accuracy: 0.5338 - val_loss: 1.2553 - val_accuracy: 0.5227\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 78s 873ms/step - loss: 1.2277 - accuracy: 0.5504 - val_loss: 1.1109 - val_accuracy: 0.5864\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 74s 839ms/step - loss: 1.1736 - accuracy: 0.5680 - val_loss: 1.4508 - val_accuracy: 0.4802\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 76s 856ms/step - loss: 1.1443 - accuracy: 0.5885 - val_loss: 2.3441 - val_accuracy: 0.3343\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 75s 843ms/step - loss: 1.0692 - accuracy: 0.6221 - val_loss: 1.3223 - val_accuracy: 0.4788\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 77s 871ms/step - loss: 1.0687 - accuracy: 0.6052 - val_loss: 2.7346 - val_accuracy: 0.2861\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 78s 879ms/step - loss: 1.0558 - accuracy: 0.6069 - val_loss: 1.0103 - val_accuracy: 0.6246\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 75s 838ms/step - loss: 1.0081 - accuracy: 0.6324 - val_loss: 1.2345 - val_accuracy: 0.5269\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 77s 859ms/step - loss: 0.9928 - accuracy: 0.6278 - val_loss: 0.9715 - val_accuracy: 0.6317\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 76s 847ms/step - loss: 0.9640 - accuracy: 0.6416 - val_loss: 0.9358 - val_accuracy: 0.6374\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 78s 872ms/step - loss: 0.9355 - accuracy: 0.6645 - val_loss: 1.5999 - val_accuracy: 0.5028\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 76s 849ms/step - loss: 0.9283 - accuracy: 0.6575 - val_loss: 2.3169 - val_accuracy: 0.3782\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 74s 834ms/step - loss: 0.9031 - accuracy: 0.6709 - val_loss: 1.0408 - val_accuracy: 0.6445\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 74s 834ms/step - loss: 0.9008 - accuracy: 0.6748 - val_loss: 1.1452 - val_accuracy: 0.5963\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 74s 825ms/step - loss: 0.8444 - accuracy: 0.6829 - val_loss: 1.1183 - val_accuracy: 0.5694\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 76s 851ms/step - loss: 0.8227 - accuracy: 0.6967 - val_loss: 1.1706 - val_accuracy: 0.6076\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 76s 857ms/step - loss: 0.7949 - accuracy: 0.6971 - val_loss: 1.0704 - val_accuracy: 0.6176\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 73s 823ms/step - loss: 0.7968 - accuracy: 0.7041 - val_loss: 1.9622 - val_accuracy: 0.4207\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 73s 817ms/step - loss: 0.7516 - accuracy: 0.7253 - val_loss: 1.4016 - val_accuracy: 0.5609\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 75s 842ms/step - loss: 0.7250 - accuracy: 0.7225 - val_loss: 0.7905 - val_accuracy: 0.7096\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 77s 861ms/step - loss: 0.7209 - accuracy: 0.7363 - val_loss: 1.1285 - val_accuracy: 0.6020\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 77s 864ms/step - loss: 0.6873 - accuracy: 0.7441 - val_loss: 1.1795 - val_accuracy: 0.6303\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 75s 836ms/step - loss: 0.6765 - accuracy: 0.7469 - val_loss: 0.8150 - val_accuracy: 0.6955\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 73s 813ms/step - loss: 0.6887 - accuracy: 0.7550 - val_loss: 1.1298 - val_accuracy: 0.6119\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 84s 946ms/step - loss: 0.6916 - accuracy: 0.7476 - val_loss: 1.0200 - val_accuracy: 0.6275\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 89s 992ms/step - loss: 0.6323 - accuracy: 0.7635 - val_loss: 0.8835 - val_accuracy: 0.7153\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 89s 996ms/step - loss: 0.6600 - accuracy: 0.7625 - val_loss: 1.4387 - val_accuracy: 0.5992\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 87s 978ms/step - loss: 0.6172 - accuracy: 0.7720 - val_loss: 1.3894 - val_accuracy: 0.5283\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 81s 907ms/step - loss: 0.5838 - accuracy: 0.7784 - val_loss: 0.9056 - val_accuracy: 0.6926\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 82s 922ms/step - loss: 0.6036 - accuracy: 0.7911 - val_loss: 1.4950 - val_accuracy: 0.5680\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 85s 955ms/step - loss: 0.5763 - accuracy: 0.7861 - val_loss: 0.9700 - val_accuracy: 0.6813\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 83s 932ms/step - loss: 0.5671 - accuracy: 0.7890 - val_loss: 1.2212 - val_accuracy: 0.6346\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 73s 820ms/step - loss: 0.5706 - accuracy: 0.7851 - val_loss: 0.8942 - val_accuracy: 0.7337\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 77s 867ms/step - loss: 0.5627 - accuracy: 0.7967 - val_loss: 0.9303 - val_accuracy: 0.6926\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 79s 889ms/step - loss: 0.5461 - accuracy: 0.7925 - val_loss: 0.8508 - val_accuracy: 0.7096\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 82s 916ms/step - loss: 0.4662 - accuracy: 0.8222 - val_loss: 1.2060 - val_accuracy: 0.5992\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 79s 887ms/step - loss: 0.5295 - accuracy: 0.8038 - val_loss: 1.4118 - val_accuracy: 0.5538\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 77s 860ms/step - loss: 0.4922 - accuracy: 0.8158 - val_loss: 0.8307 - val_accuracy: 0.7295\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 76s 855ms/step - loss: 0.4784 - accuracy: 0.8218 - val_loss: 0.9084 - val_accuracy: 0.7224\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 78s 872ms/step - loss: 0.4289 - accuracy: 0.8388 - val_loss: 0.7631 - val_accuracy: 0.7550\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 78s 880ms/step - loss: 0.4452 - accuracy: 0.8374 - val_loss: 1.0418 - val_accuracy: 0.6714\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 80s 903ms/step - loss: 0.4724 - accuracy: 0.8360 - val_loss: 1.6844 - val_accuracy: 0.6190\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 80s 901ms/step - loss: 0.4167 - accuracy: 0.8445 - val_loss: 0.8206 - val_accuracy: 0.7450\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 81s 908ms/step - loss: 0.4024 - accuracy: 0.8494 - val_loss: 0.9481 - val_accuracy: 0.6841\n",
            "Epoch 51/200\n",
            "89/89 [==============================] - 83s 926ms/step - loss: 0.4055 - accuracy: 0.8431 - val_loss: 0.9502 - val_accuracy: 0.7195\n",
            "Epoch 52/200\n",
            "89/89 [==============================] - 84s 938ms/step - loss: 0.3938 - accuracy: 0.8487 - val_loss: 1.1797 - val_accuracy: 0.6601\n",
            "Epoch 53/200\n",
            "89/89 [==============================] - 76s 860ms/step - loss: 0.4128 - accuracy: 0.8459 - val_loss: 1.0441 - val_accuracy: 0.6884\n",
            "Epoch 54/200\n",
            "89/89 [==============================] - 74s 831ms/step - loss: 0.4506 - accuracy: 0.8367 - val_loss: 0.8424 - val_accuracy: 0.7153\n",
            "Epoch 55/200\n",
            "89/89 [==============================] - 72s 810ms/step - loss: 0.4203 - accuracy: 0.8420 - val_loss: 1.4537 - val_accuracy: 0.6459\n",
            "Epoch 56/200\n",
            "89/89 [==============================] - 77s 863ms/step - loss: 0.3367 - accuracy: 0.8749 - val_loss: 0.9911 - val_accuracy: 0.6912\n",
            "Epoch 57/200\n",
            "89/89 [==============================] - 74s 832ms/step - loss: 0.3819 - accuracy: 0.8572 - val_loss: 0.9439 - val_accuracy: 0.7054\n",
            "Epoch 58/200\n",
            "89/89 [==============================] - 70s 792ms/step - loss: 0.3512 - accuracy: 0.8727 - val_loss: 1.2840 - val_accuracy: 0.6601\n",
            "Epoch 59/200\n",
            "89/89 [==============================] - 71s 793ms/step - loss: 0.3462 - accuracy: 0.8682 - val_loss: 0.8085 - val_accuracy: 0.7465\n",
            "Epoch 60/200\n",
            "89/89 [==============================] - 73s 816ms/step - loss: 0.3612 - accuracy: 0.8713 - val_loss: 1.1154 - val_accuracy: 0.6799\n",
            "Epoch 61/200\n",
            "89/89 [==============================] - 74s 836ms/step - loss: 0.3135 - accuracy: 0.8834 - val_loss: 0.8070 - val_accuracy: 0.7479\n",
            "Epoch 62/200\n",
            "89/89 [==============================] - 74s 826ms/step - loss: 0.3472 - accuracy: 0.8788 - val_loss: 0.8681 - val_accuracy: 0.7479\n",
            "Epoch 63/200\n",
            "89/89 [==============================] - 72s 809ms/step - loss: 0.3669 - accuracy: 0.8759 - val_loss: 1.3407 - val_accuracy: 0.6360\n",
            "Epoch 64/200\n",
            "89/89 [==============================] - 72s 810ms/step - loss: 0.3290 - accuracy: 0.8805 - val_loss: 0.9065 - val_accuracy: 0.7323\n",
            "Epoch 65/200\n",
            "89/89 [==============================] - 73s 818ms/step - loss: 0.3286 - accuracy: 0.8841 - val_loss: 1.0176 - val_accuracy: 0.7181\n",
            "Epoch 66/200\n",
            "89/89 [==============================] - 74s 832ms/step - loss: 0.3372 - accuracy: 0.8763 - val_loss: 1.0542 - val_accuracy: 0.7011\n",
            "Epoch 67/200\n",
            "89/89 [==============================] - 73s 820ms/step - loss: 0.2794 - accuracy: 0.8890 - val_loss: 0.9127 - val_accuracy: 0.7535\n",
            "Epoch 68/200\n",
            "89/89 [==============================] - 70s 790ms/step - loss: 0.2788 - accuracy: 0.8915 - val_loss: 0.9513 - val_accuracy: 0.7422\n",
            "Epoch 69/200\n",
            "89/89 [==============================] - 69s 776ms/step - loss: 0.2971 - accuracy: 0.8964 - val_loss: 1.0713 - val_accuracy: 0.7337\n",
            "Epoch 70/200\n",
            "89/89 [==============================] - 71s 793ms/step - loss: 0.3041 - accuracy: 0.8943 - val_loss: 1.0691 - val_accuracy: 0.6969\n",
            "Epoch 71/200\n",
            "89/89 [==============================] - 70s 786ms/step - loss: 0.3038 - accuracy: 0.8879 - val_loss: 1.0100 - val_accuracy: 0.7153\n",
            "Epoch 72/200\n",
            "89/89 [==============================] - 67s 756ms/step - loss: 0.2877 - accuracy: 0.8883 - val_loss: 1.4946 - val_accuracy: 0.6671\n",
            "Epoch 73/200\n",
            "89/89 [==============================] - 67s 748ms/step - loss: 0.2553 - accuracy: 0.9021 - val_loss: 0.7939 - val_accuracy: 0.7776\n",
            "Epoch 74/200\n",
            "89/89 [==============================] - 68s 765ms/step - loss: 0.2463 - accuracy: 0.9095 - val_loss: 0.9643 - val_accuracy: 0.7323\n",
            "Epoch 75/200\n",
            "89/89 [==============================] - 72s 808ms/step - loss: 0.2388 - accuracy: 0.9109 - val_loss: 0.8847 - val_accuracy: 0.7351\n",
            "Epoch 76/200\n",
            "89/89 [==============================] - 72s 808ms/step - loss: 0.2510 - accuracy: 0.9049 - val_loss: 0.8618 - val_accuracy: 0.7904\n",
            "Epoch 77/200\n",
            "89/89 [==============================] - 69s 776ms/step - loss: 0.2291 - accuracy: 0.9166 - val_loss: 1.1068 - val_accuracy: 0.7337\n",
            "Epoch 78/200\n",
            "89/89 [==============================] - 71s 796ms/step - loss: 0.2763 - accuracy: 0.8982 - val_loss: 1.0102 - val_accuracy: 0.7521\n",
            "Epoch 79/200\n",
            "89/89 [==============================] - 85s 951ms/step - loss: 0.2565 - accuracy: 0.9046 - val_loss: 1.0777 - val_accuracy: 0.7323\n",
            "Epoch 80/200\n",
            "89/89 [==============================] - 78s 882ms/step - loss: 0.2502 - accuracy: 0.9127 - val_loss: 1.0315 - val_accuracy: 0.7167\n",
            "Epoch 81/200\n",
            "89/89 [==============================] - 80s 893ms/step - loss: 0.2417 - accuracy: 0.9138 - val_loss: 1.0580 - val_accuracy: 0.7011\n",
            "Epoch 82/200\n",
            "89/89 [==============================] - 76s 852ms/step - loss: 0.2591 - accuracy: 0.9092 - val_loss: 1.6708 - val_accuracy: 0.6232\n",
            "Epoch 83/200\n",
            "89/89 [==============================] - 74s 828ms/step - loss: 0.2553 - accuracy: 0.9074 - val_loss: 0.8970 - val_accuracy: 0.7550\n",
            "Epoch 84/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.2646 - accuracy: 0.9014 - val_loss: 0.9421 - val_accuracy: 0.7550\n",
            "Epoch 85/200\n",
            "89/89 [==============================] - 113s 1s/step - loss: 0.2623 - accuracy: 0.9116 - val_loss: 1.0851 - val_accuracy: 0.6841\n",
            "Epoch 86/200\n",
            "89/89 [==============================] - 108s 1s/step - loss: 0.1964 - accuracy: 0.9205 - val_loss: 0.8811 - val_accuracy: 0.7734\n",
            "Epoch 87/200\n",
            "89/89 [==============================] - 107s 1s/step - loss: 0.2189 - accuracy: 0.9208 - val_loss: 0.9172 - val_accuracy: 0.7734\n",
            "Epoch 88/200\n",
            "89/89 [==============================] - 102s 1s/step - loss: 0.2061 - accuracy: 0.9290 - val_loss: 0.8970 - val_accuracy: 0.7578\n",
            "Epoch 89/200\n",
            "89/89 [==============================] - 106s 1s/step - loss: 0.2014 - accuracy: 0.9233 - val_loss: 1.0426 - val_accuracy: 0.7422\n",
            "Epoch 90/200\n",
            "89/89 [==============================] - 105s 1s/step - loss: 0.2028 - accuracy: 0.9275 - val_loss: 0.9905 - val_accuracy: 0.7776\n",
            "Epoch 91/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.2069 - accuracy: 0.9279 - val_loss: 1.2442 - val_accuracy: 0.7238\n",
            "Epoch 92/200\n",
            "89/89 [==============================] - 97s 1s/step - loss: 0.2233 - accuracy: 0.9180 - val_loss: 1.2819 - val_accuracy: 0.7266\n",
            "Epoch 93/200\n",
            "89/89 [==============================] - 96s 1s/step - loss: 0.2327 - accuracy: 0.9141 - val_loss: 0.8840 - val_accuracy: 0.7521\n",
            "Epoch 94/200\n",
            "89/89 [==============================] - 99s 1s/step - loss: 0.2050 - accuracy: 0.9212 - val_loss: 0.9271 - val_accuracy: 0.7918\n",
            "Epoch 95/200\n",
            "89/89 [==============================] - 94s 1s/step - loss: 0.1744 - accuracy: 0.9346 - val_loss: 1.9471 - val_accuracy: 0.5892\n",
            "Epoch 96/200\n",
            "89/89 [==============================] - 94s 1s/step - loss: 0.2097 - accuracy: 0.9268 - val_loss: 1.0335 - val_accuracy: 0.7493\n",
            "Epoch 97/200\n",
            "89/89 [==============================] - 95s 1s/step - loss: 0.2059 - accuracy: 0.9236 - val_loss: 0.7861 - val_accuracy: 0.7918\n",
            "Epoch 98/200\n",
            "89/89 [==============================] - 95s 1s/step - loss: 0.1751 - accuracy: 0.9385 - val_loss: 1.0149 - val_accuracy: 0.7734\n",
            "Epoch 99/200\n",
            "89/89 [==============================] - 95s 1s/step - loss: 0.1671 - accuracy: 0.9360 - val_loss: 1.1740 - val_accuracy: 0.7224\n",
            "Epoch 100/200\n",
            "89/89 [==============================] - 95s 1s/step - loss: 0.1928 - accuracy: 0.9346 - val_loss: 0.9229 - val_accuracy: 0.7635\n",
            "Epoch 101/200\n",
            "89/89 [==============================] - 94s 1s/step - loss: 0.1801 - accuracy: 0.9381 - val_loss: 0.9916 - val_accuracy: 0.7677\n",
            "Epoch 102/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.2056 - accuracy: 0.9229 - val_loss: 1.0339 - val_accuracy: 0.7479\n",
            "Epoch 103/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.1708 - accuracy: 0.9417 - val_loss: 1.1183 - val_accuracy: 0.7436\n",
            "Epoch 104/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1548 - accuracy: 0.9424 - val_loss: 1.0171 - val_accuracy: 0.7663\n",
            "Epoch 105/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1729 - accuracy: 0.9392 - val_loss: 0.9505 - val_accuracy: 0.7805\n",
            "Epoch 106/200\n",
            "89/89 [==============================] - 102s 1s/step - loss: 0.2028 - accuracy: 0.9272 - val_loss: 1.0282 - val_accuracy: 0.7592\n",
            "Epoch 107/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1888 - accuracy: 0.9343 - val_loss: 0.9806 - val_accuracy: 0.7394\n",
            "Epoch 108/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1615 - accuracy: 0.9381 - val_loss: 0.9418 - val_accuracy: 0.7734\n",
            "Epoch 109/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1345 - accuracy: 0.9459 - val_loss: 1.0515 - val_accuracy: 0.7635\n",
            "Epoch 110/200\n",
            "89/89 [==============================] - 100s 1s/step - loss: 0.1512 - accuracy: 0.9466 - val_loss: 1.1789 - val_accuracy: 0.7479\n",
            "Epoch 111/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1497 - accuracy: 0.9505 - val_loss: 1.2700 - val_accuracy: 0.6983\n",
            "Epoch 112/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1720 - accuracy: 0.9410 - val_loss: 1.0139 - val_accuracy: 0.7351\n",
            "Epoch 113/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1644 - accuracy: 0.9371 - val_loss: 1.4253 - val_accuracy: 0.6912\n",
            "Epoch 114/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1514 - accuracy: 0.9420 - val_loss: 1.1588 - val_accuracy: 0.7493\n",
            "Epoch 115/200\n",
            "89/89 [==============================] - 99s 1s/step - loss: 0.1612 - accuracy: 0.9424 - val_loss: 1.1104 - val_accuracy: 0.7479\n",
            "Epoch 116/200\n",
            "89/89 [==============================] - 97s 1s/step - loss: 0.1688 - accuracy: 0.9424 - val_loss: 1.1937 - val_accuracy: 0.7479\n",
            "Epoch 117/200\n",
            "89/89 [==============================] - 102s 1s/step - loss: 0.1852 - accuracy: 0.9381 - val_loss: 1.2650 - val_accuracy: 0.6898\n",
            "Epoch 118/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1634 - accuracy: 0.9403 - val_loss: 1.3211 - val_accuracy: 0.6756\n",
            "Epoch 119/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.1467 - accuracy: 0.9449 - val_loss: 0.8181 - val_accuracy: 0.8130\n",
            "Epoch 120/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1786 - accuracy: 0.9385 - val_loss: 1.1906 - val_accuracy: 0.7238\n",
            "Epoch 121/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.1540 - accuracy: 0.9463 - val_loss: 0.8493 - val_accuracy: 0.7960\n",
            "Epoch 122/200\n",
            "89/89 [==============================] - 100s 1s/step - loss: 0.1330 - accuracy: 0.9509 - val_loss: 0.8913 - val_accuracy: 0.7861\n",
            "Epoch 123/200\n",
            "89/89 [==============================] - 101s 1s/step - loss: 0.1241 - accuracy: 0.9579 - val_loss: 1.0304 - val_accuracy: 0.7946\n",
            "Epoch 124/200\n",
            "89/89 [==============================] - 95s 1s/step - loss: 0.1210 - accuracy: 0.9551 - val_loss: 1.2574 - val_accuracy: 0.7408\n",
            "Epoch 125/200\n",
            "89/89 [==============================] - 94s 1s/step - loss: 0.1543 - accuracy: 0.9491 - val_loss: 0.9970 - val_accuracy: 0.7946\n",
            "Epoch 126/200\n",
            "89/89 [==============================] - 101s 1s/step - loss: 0.1843 - accuracy: 0.9385 - val_loss: 1.0068 - val_accuracy: 0.7465\n",
            "Epoch 127/200\n",
            "89/89 [==============================] - 97s 1s/step - loss: 0.1414 - accuracy: 0.9470 - val_loss: 1.1626 - val_accuracy: 0.7465\n",
            "Epoch 128/200\n",
            "89/89 [==============================] - 91s 1s/step - loss: 0.1637 - accuracy: 0.9374 - val_loss: 1.3904 - val_accuracy: 0.7139\n",
            "Epoch 129/200\n",
            "89/89 [==============================] - 107s 1s/step - loss: 0.1469 - accuracy: 0.9477 - val_loss: 2.8801 - val_accuracy: 0.5368\n",
            "Epoch 130/200\n",
            "89/89 [==============================] - 102s 1s/step - loss: 0.1550 - accuracy: 0.9491 - val_loss: 0.9658 - val_accuracy: 0.7734\n",
            "Epoch 131/200\n",
            "89/89 [==============================] - 107s 1s/step - loss: 0.1337 - accuracy: 0.9487 - val_loss: 1.1496 - val_accuracy: 0.7833\n",
            "Epoch 132/200\n",
            "89/89 [==============================] - 100s 1s/step - loss: 0.1393 - accuracy: 0.9540 - val_loss: 0.9763 - val_accuracy: 0.7677\n",
            "Epoch 133/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1290 - accuracy: 0.9530 - val_loss: 1.0882 - val_accuracy: 0.7592\n",
            "Epoch 134/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1877 - accuracy: 0.9374 - val_loss: 1.3664 - val_accuracy: 0.7011\n",
            "Epoch 135/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1511 - accuracy: 0.9420 - val_loss: 1.3944 - val_accuracy: 0.7167\n",
            "Epoch 136/200\n",
            "89/89 [==============================] - 105s 1s/step - loss: 0.1715 - accuracy: 0.9434 - val_loss: 0.9256 - val_accuracy: 0.7691\n",
            "Epoch 137/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1862 - accuracy: 0.9297 - val_loss: 1.5176 - val_accuracy: 0.6912\n",
            "Epoch 138/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.1491 - accuracy: 0.9509 - val_loss: 0.8657 - val_accuracy: 0.8059\n",
            "Epoch 139/200\n",
            "89/89 [==============================] - 99s 1s/step - loss: 0.0915 - accuracy: 0.9643 - val_loss: 1.3749 - val_accuracy: 0.6997\n",
            "Epoch 140/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.1571 - accuracy: 0.9459 - val_loss: 1.3705 - val_accuracy: 0.6657\n",
            "Epoch 141/200\n",
            "89/89 [==============================] - 97s 1s/step - loss: 0.1334 - accuracy: 0.9530 - val_loss: 1.0880 - val_accuracy: 0.7181\n",
            "Epoch 142/200\n",
            "89/89 [==============================] - 101s 1s/step - loss: 0.1425 - accuracy: 0.9516 - val_loss: 0.9254 - val_accuracy: 0.7890\n",
            "Epoch 143/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.1008 - accuracy: 0.9629 - val_loss: 1.2182 - val_accuracy: 0.7295\n",
            "Epoch 144/200\n",
            "89/89 [==============================] - 102s 1s/step - loss: 0.1299 - accuracy: 0.9533 - val_loss: 1.0479 - val_accuracy: 0.7493\n",
            "Epoch 145/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1375 - accuracy: 0.9502 - val_loss: 1.0584 - val_accuracy: 0.7606\n",
            "Epoch 146/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1112 - accuracy: 0.9597 - val_loss: 1.3368 - val_accuracy: 0.7238\n",
            "Epoch 147/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1266 - accuracy: 0.9519 - val_loss: 0.9931 - val_accuracy: 0.7635\n",
            "Epoch 148/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1044 - accuracy: 0.9597 - val_loss: 1.2119 - val_accuracy: 0.7479\n",
            "Epoch 149/200\n",
            "89/89 [==============================] - 100s 1s/step - loss: 0.0906 - accuracy: 0.9650 - val_loss: 1.6051 - val_accuracy: 0.6997\n",
            "Epoch 150/200\n",
            "89/89 [==============================] - 102s 1s/step - loss: 0.1059 - accuracy: 0.9601 - val_loss: 0.9611 - val_accuracy: 0.8045\n",
            "Epoch 151/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1169 - accuracy: 0.9586 - val_loss: 1.0570 - val_accuracy: 0.7734\n",
            "Epoch 152/200\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.1255 - accuracy: 0.9565 - val_loss: 0.9973 - val_accuracy: 0.7705\n",
            "Epoch 153/200\n",
            "89/89 [==============================] - 102s 1s/step - loss: 0.1689 - accuracy: 0.9410 - val_loss: 1.0656 - val_accuracy: 0.7691\n",
            "Epoch 154/200\n",
            "89/89 [==============================] - 104s 1s/step - loss: 0.1423 - accuracy: 0.9519 - val_loss: 0.9311 - val_accuracy: 0.7748\n",
            "Epoch 155/200\n",
            "89/89 [==============================] - 98s 1s/step - loss: 0.1119 - accuracy: 0.9562 - val_loss: 0.9310 - val_accuracy: 0.7904\n",
            "Epoch 156/200\n",
            "89/89 [==============================] - 96s 1s/step - loss: 0.1458 - accuracy: 0.9484 - val_loss: 1.2898 - val_accuracy: 0.7110\n",
            "Epoch 157/200\n",
            "89/89 [==============================] - 96s 1s/step - loss: 0.1727 - accuracy: 0.9403 - val_loss: 0.8934 - val_accuracy: 0.7847\n",
            "Epoch 158/200\n",
            "89/89 [==============================] - 95s 1s/step - loss: 0.1262 - accuracy: 0.9537 - val_loss: 1.3895 - val_accuracy: 0.6756\n",
            "Epoch 159/200\n",
            "89/89 [==============================] - 99s 1s/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 1.0360 - val_accuracy: 0.7932\n",
            "Epoch 160/200\n",
            "89/89 [==============================] - 100s 1s/step - loss: 0.0888 - accuracy: 0.9654 - val_loss: 1.1123 - val_accuracy: 0.7776\n",
            "Epoch 161/200\n",
            "89/89 [==============================] - 96s 1s/step - loss: 0.0965 - accuracy: 0.9696 - val_loss: 1.8216 - val_accuracy: 0.6827\n",
            "Epoch 162/200\n",
            "89/89 [==============================] - 101s 1s/step - loss: 0.1495 - accuracy: 0.9523 - val_loss: 1.4784 - val_accuracy: 0.7125\n",
            "Epoch 163/200\n",
            "89/89 [==============================] - 63s 704ms/step - loss: 0.1377 - accuracy: 0.9516 - val_loss: 1.7442 - val_accuracy: 0.6586\n",
            "Epoch 164/200\n",
            "89/89 [==============================] - 46s 519ms/step - loss: 0.1487 - accuracy: 0.9491 - val_loss: 1.1945 - val_accuracy: 0.7507\n",
            "Epoch 165/200\n",
            "89/89 [==============================] - 46s 521ms/step - loss: 0.1216 - accuracy: 0.9618 - val_loss: 1.3706 - val_accuracy: 0.7068\n",
            "Epoch 166/200\n",
            "89/89 [==============================] - 45s 508ms/step - loss: 0.0979 - accuracy: 0.9654 - val_loss: 1.0427 - val_accuracy: 0.7932\n",
            "Epoch 167/200\n",
            "89/89 [==============================] - 45s 508ms/step - loss: 0.1105 - accuracy: 0.9597 - val_loss: 1.0423 - val_accuracy: 0.7847\n",
            "Epoch 168/200\n",
            "89/89 [==============================] - 45s 508ms/step - loss: 0.1000 - accuracy: 0.9629 - val_loss: 1.1414 - val_accuracy: 0.7649\n",
            "Epoch 169/200\n",
            "89/89 [==============================] - 45s 510ms/step - loss: 0.1302 - accuracy: 0.9544 - val_loss: 1.1198 - val_accuracy: 0.7550\n"
          ]
        }
      ],
      "source": [
        "# Create folders and callbacks and fit\n",
        "callbacks = create_folders_and_callbacks(model_name='CNN_17_11_1')\n",
        "\n",
        "epochs = 200\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = val_gen,\n",
        "    class_weight = class_weight,\n",
        "    callbacks = callbacks,\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8_RZcNnAz-G8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Cnn_best_weights/Cnn_best_weights\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Cnn_best_weights/Cnn_best_weights\\assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"Cnn_best_weights/Cnn_best_weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GQamADdl0DYC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 2s 68ms/step - loss: 0.8181 - accuracy: 0.8130\n",
            "\n",
            "Test metrics without data augmentation\n",
            "{'loss': 0.8181033134460449, 'accuracy': 0.8130311369895935}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "\n",
        "model_test_metrics = model.evaluate(val_gen, return_dict=True)\n",
        "\n",
        "print()\n",
        "print(\"Test metrics with weights and data augmentation\")\n",
        "print(model_test_metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "f1838362fc3c72254db1311c9d5db56b79b6520b93de3800103ebfd8112b592e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
